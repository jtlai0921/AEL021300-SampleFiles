## Python Codes for Chapter 7: Scientific Library: Scipy

#########

import numpy as np
import scipy 

scipy.__version__

np.info(scipy)

help(scipy)  # right-click to preview

import scipy.optimize

np.lookfor("roots", scipy.optimize)

import numpy as np
import scipy.optimize

np.info(scipy.optimize)  # right-click to preview

help(scipy.optimize)  # right-click to preview

import numpy as np

from scipy.optimize import fsolve

help(fsolve)  # Find the roots of a function.

f = lambda x: x**3 + 2 * x**2 - 7
root = fsolve(f, 1.0)  # 1.0 is the starting estimate for the root
root

f(root)

np.roots([1, 2, 0, -7])

f = lambda x: x**3 + 2 * x**2 - 7
g = lambda x: x + 2

intersection = fsolve(lambda x: f(x) - g(x), 1.0)
intersection

f(intersection); g(intersection)

from scipy.optimize import minimize

f = lambda x: np.exp(-x) + x**4

minimize(f, 1.0)

from scipy.optimize import minimize_scalar

minimize_scalar(f)

x = np.array([1, 2.5, 3.6, 3.2, 5.5])
y = np.array([-2.5, 3.3, 0, 2.2, -7])

from scipy.optimize import curve_fit

f = lambda x, b0, b1: b0 + b1 * x
par_est, cov_est = curve_fit(f, x, y)

par_est

cov_est

g = lambda x, b0, b1, b2: b0 + b1 * x + b2 * x**2
par_est, cov_est = curve_fit(g, x, y)

par_est

cov_est

import numpy as np
import scipy.integrate 

np.info(scipy.integrate)  

help(scipy.integrate)  # right-click to preview

import numpy as np
from scipy.integrate import quad

f = lambda x: np.exp(-x) 
integral, error = quad(f, 1, 3)

integral

error

np.exp(-1) - np.exp(-3)

g = lambda x: 4 * np.sqrt(1 - x**2)

quad(g, 0, 1)[0]

np.pi

f = lambda u, x: 1/np.sqrt(2 * np.pi) * x * np.exp(-(x * u)**2 / 2)

def cdf(x):
	y = np.zeros(len(x))
	for i in range(len(x)):
		y[i] = np.where(x[i] == 0, 0.5, 0.5 + quad(f, 0, 1, args = (x[i],))[0])
	return y

x = np.array([-0.5, 0, 0.5])
cdf(x)

from scipy.stats import norm

x = np.array([-0.5, 0, 0.5])
distribution = norm(loc = 0, scale = 1)
cdf_value = distribution.cdf(x)
cdf_value

import numpy as np
from scipy.integrate import quad, trapz

g = lambda x: 4 * np.sqrt(1 - x**2)

np.random.seed(1)
x = np.sort(np.random.uniform(size = 100))
y = g(x)

trapz(y, x = x)  # using the composite trapezoidal rule

quad(g, 0, 1)[0]

from scipy.integrate import odeint
import matplotlib.pyplot as plt

def f(x, t): # return derivatives of the array x
	return np.array([-x[1], x[0] + (1 - x[0]**2) * x[1]])

time = np.linspace(0.0, 50.0, 5000)
x0 = np.array([0.1, 0.2])  # initial states

state = odeint(f, x0, time)

plt.figure(figsize = (6, 6))
plt.plot(time, state[:, 0], "r-", label = "x1") 
plt.plot(time, state[:, 1], "b:", label = "x2")
plt.title("state trajectories")
plt.xlabel("time")
plt.ylabel("states")
plt.axis([-1, 51, -4, 4])
plt.legend(loc = "upper left", fontsize = 12)
plt.show()

plt.figure(figsize = (6, 6))
plt.plot(state[:, 0], state[:, 1])
plt.title("phase trajectory")
plt.xlabel("x1")
plt.ylabel("x2")
plt.show()

from scipy.integrate import odeint
import matplotlib.pyplot as plt

c = 0.1; k = 1; omega = 2
def f(x, t): # return derivatives of the array x
	return np.array([x[1], -x[0]**3 - c * x[1] + k * np.cos(omega * t)])

time = np.linspace(0.0, 50.0, 5000)
x0 = np.array([0.1, 0.2])  # initial states

state = odeint(f, x0, time)

plt.figure(figsize = (6, 6))
plt.plot(time, state[:, 0], "r-", label = "x1") 
plt.plot(time, state[:, 1], "b:", label = "x2")
plt.title("state trajectories")
plt.xlabel("time")
plt.ylabel("states")
plt.axis([-1, 51, -1, 1])
plt.legend(loc = "upper right", fontsize = 12)
plt.show()

plt.figure(figsize = (6, 6))
plt.plot(state[:, 0], state[:, 1])
plt.title("phase trajectory")
plt.xlabel("x1")
plt.ylabel("x2")
plt.show()

from scipy.integrate import odeint
import matplotlib.pyplot as plt

sigma = 10; r = 28; b = 8/3
def f(x, t): # return derivatives of the array x
	return np.array([sigma * (x[1] - x[0]), r * x[0] - x[1] - x[0] * x[2], x[0] * x[1] - b * x[2]])

time = np.linspace(0.0, 50.0, 5000)
x0 = np.array([15, 10, 40])  # initial states

state = odeint(f, x0, time)

plt.figure(figsize = (6, 6))
plt.plot(time, state[:, 0], "r-", label = "x") 
plt.plot(time, state[:, 1], "g:", label = "y")
plt.plot(time, state[:, 2], "b-.", label = "z")
plt.title("state trajectories")
plt.xlabel("time")
plt.ylabel("states")
plt.axis([-1, 51, -25, 45])
plt.legend(loc = "upper left", fontsize = 12)
plt.show()

plt.figure(figsize = (6, 6))
plt.plot(state[:, 0], state[:, 1])
plt.title("phase trajectory")
plt.xlabel("x")
plt.ylabel("y")
plt.show()

plt.figure(figsize = (6, 6))
plt.plot(state[:, 1], state[:, 2])
plt.title("phase trajectory")
plt.xlabel("y")
plt.ylabel("z")
plt.show()

plt.figure(figsize = (6, 6))
plt.plot(state[:, 0], state[:, 2])
plt.title("phase trajectory")
plt.xlabel("x")
plt.ylabel("z")
plt.show()

import numpy as np
import scipy.interpolate

np.info(scipy.interpolate)  # right-click to preview

help(scipy.interpolate)  # right-click to preview

from scipy.interpolate import interp1d
import matplotlib.pyplot as plt

f = lambda x: np.cos(x) + x

np.random.seed(1)
x = np.random.uniform(low = 0, high = 5, size = 20)
y = f(x)

g1 = interp1d(x, y, kind = "linear")
g2 = interp1d(x, y, kind = "quadratic")

x0 = np.linspace(np.min(x), np.max(x), 100)
y0 = f(x0)
y1 = g1(x0)
y2 = g2(x0)

plt.figure(figsize = (6, 6))
plt.plot(x, y, "wo", label = "data") 
plt.plot(x0, y0, "r-", label = "true") 
plt.plot(x0, y1, "g-.", label = "linear") 
plt.plot(x0, y2, "b:", label = "quadratic")
plt.xlabel("x")
plt.ylabel("y")
ymin = min(min(y0), min(y1), min(y2))
ymax = max(max(y0), max(y1), max(y2))
plt.axis([-1, 6, ymin - 0.5, ymax + 0.5])
plt.legend(loc = "upper left", fontsize = 12)
plt.show()

from scipy.interpolate import UnivariateSpline
import matplotlib.pyplot as plt

f = lambda x: np.cos(x) + x

np.random.seed(1)
x = np.random.uniform(low = 0, high = 5, size = 20)
yn = f(x) + np.random.normal(size = 20) / 10

h1 = UnivariateSpline(x, yn, k = 2)
h2 = UnivariateSpline(x, yn, k = 3)

x0 = np.linspace(np.min(x), np.max(x), 100)
y0 = f(x0)
yn1 = h1(x0) 
yn2 = h2(x0) 

plt.figure(figsize = (6, 6))
plt.plot(x, yn, "wo", label = "data") 
plt.plot(x0, y0, "r-", label = "true") 
plt.plot(x0, yn1, "g-.", label = "quadratic") 
plt.plot(x0, yn2, "b:", label = "cubic")
plt.xlabel("x")
plt.ylabel("y")
ymin = min(min(y0), min(yn1), min(yn2))
ymax = max(min(y0), max(yn1), max(yn2))
plt.axis([-1, 6, ymin - 0.5, ymax + 0.5])
plt.legend(loc = "upper left", fontsize = 12)
plt.show()

import numpy as np
import scipy.stats as stats

np.info(stats)  # right-click to preview

help(stats)  # right-click to preview

import scipy.stats as stats

rv = stats.randint(low = 5, high = 10)

rv.pmf([5, 6, 7, 8, 9])

rv.pmf([4, 5, 6, 7, 8, 9, 10])

rv.cdf([5, 6, 7, 8, 9])

rv.cdf([4, 5, 6, 7, 8, 9, 10])

rv.ppf([0.25, 0.5, 0.75])

np.random.seed(1)
rv.rvs(5)  

rv = stats.binom(n = 10, p = 0.4)

rv = stats.poisson(mu = 6.0)

rv = stats.geom(p = 0.2)

rv = stats.uniform(loc = 0, scale = 1)

rv = stats.uniform(loc = 2, scale = 3)  # constant in [loc, loc+scale] 

rv = stats.norm(loc = 0, scale = 1)

x = np.array([-0.5, 0, 0.5])

rv.pdf(x)

rv.cdf(x)

rv.ppf([0.25, 0.5, 0.75])  

np.random.seed(1)
rv.rvs(3)  

rv = stats.norm(loc = 1.5, scale = 4)

rv = stats.expon(scale = 2)

np.random.seed(1)
x = np.random.normal(size = 100)

quick_look = stats.describe(x)

print('\nSize = ' + str(quick_look[0]))

print('Minimim = ' + str(quick_look[1][0]))

print('Maximum = ' + str(quick_look[1][1]))

print('Mean = ' + str(quick_look[2]))

print('Variance = ' + str(quick_look[3]))

print('Skewness = ' + str(quick_look[4]))

print('Kurtosis = ' + str(quick_look[5]))

np.random.seed(1)
x = np.random.normal(size = 100)
y = np.random.uniform(low = -10, high = 10, size = 100)
z = stats.t.rvs(df = 30, size = 100)

z_score, p_value = stats.normaltest(x)
p_value

z_score, p_value = stats.normaltest(y)
p_value

z_score, p_value = stats.normaltest(z)
p_value

D, p_value = stats.kstest(x, "norm")  # against normal distribution
p_value

D, p_value = stats.kstest(y, "norm")
p_value

D, p_value = stats.kstest(z, "norm")
p_value

D, p_value = stats.kstest(x, "laplace")  # vs Laplace distribution
p_value

D, p_value = stats.kstest(y, "expon")  # vs exponential distribution
p_value

D, p_value = stats.kstest(z, "wald")  # vs Wald distribution
p_value

#########
